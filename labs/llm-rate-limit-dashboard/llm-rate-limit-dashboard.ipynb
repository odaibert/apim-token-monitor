{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Token Rate Limiting Lab with Azure API Management\n",
    "\n",
    "This lab demonstrates implementing **token-based rate limiting** using Azure API Management's `llm-token-limit` policy with Azure OpenAI.\n",
    "\n",
    "## ðŸŽ¯ What You'll Learn\n",
    "- Deploy Azure APIM (BasicV2 SKU) as an AI Gateway\n",
    "- Deploy Azure OpenAI with GPT-4o-mini model\n",
    "- Configure token-based rate limiting (500 TPM)\n",
    "- Monitor and test rate limiting behavior\n",
    "\n",
    "## ðŸ“š Official Microsoft Documentation & Learning Resources\n",
    "\n",
    "| Resource | Description |\n",
    "|----------|-------------|\n",
    "| [Azure API Management GenAI Gateway](https://learn.microsoft.com/azure/api-management/genai-gateway-capabilities) | Overview of AI gateway capabilities in APIM |\n",
    "| [llm-token-limit Policy](https://learn.microsoft.com/azure/api-management/llm-token-limit-policy) | Official docs for token-based rate limiting policy |\n",
    "| [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview) | Azure OpenAI documentation |\n",
    "| [APIM Pricing Tiers](https://learn.microsoft.com/azure/api-management/api-management-features) | Understanding APIM SKUs (BasicV2 used here) |\n",
    "| [MS Learn: Implement API Management](https://learn.microsoft.com/training/modules/explore-api-management/) | Free training module on APIM |\n",
    "| [MS Learn: Azure OpenAI](https://learn.microsoft.com/training/paths/develop-ai-solutions-azure-openai/) | Learning path for Azure OpenAI |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                              Azure Subscription                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚                    Resource Group: lab-token-rate-limiting                â”‚  â”‚\n",
    "â”‚  â”‚                                                                           â”‚  â”‚\n",
    "â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚\n",
    "â”‚  â”‚   â”‚   Client    â”‚         â”‚   Azure API Mgmt     â”‚         â”‚  Azure   â”‚  â”‚  â”‚\n",
    "â”‚  â”‚   â”‚ Application â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚   (BasicV2 SKU)      â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  OpenAI  â”‚  â”‚  â”‚\n",
    "â”‚  â”‚   â”‚             â”‚ HTTP(S) â”‚                      â”‚  HTTP   â”‚          â”‚  â”‚  â”‚\n",
    "â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚ GPT-4o-  â”‚  â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â”‚ llm-token-limitâ”‚  â”‚         â”‚  mini    â”‚  â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â”‚    Policy      â”‚  â”‚         â”‚          â”‚  â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â”‚  (500 TPM)     â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                       â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚                      â”‚                       â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  Features:           â”‚                       â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â€¢ Token counting    â”‚                       â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â€¢ Rate enforcement  â”‚                       â”‚  â”‚\n",
    "â”‚  â”‚                           â”‚  â€¢ 429 responses     â”‚                       â”‚  â”‚\n",
    "â”‚  â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚  â”‚\n",
    "â”‚  â”‚                                                                           â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### How Token Rate Limiting Works\n",
    "\n",
    "1. **Client Request**: Application sends a chat completion request to APIM\n",
    "2. **Token Estimation**: APIM estimates tokens in the request using a built-in tokenizer\n",
    "3. **Rate Check**: The `llm-token-limit` policy checks against the 500 TPM quota\n",
    "4. **Response Counting**: Response tokens are counted and added to the consumption total\n",
    "5. **Enforcement**: If limit exceeded, APIM returns `429 Too Many Requests`\n",
    "\n",
    "> ðŸ“– **Learn more**: [How token limiting works](https://learn.microsoft.com/azure/api-management/llm-token-limit-policy#how-token-limiting-works)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Prerequisites\n",
    "\n",
    "| Requirement | Description | Documentation |\n",
    "|-------------|-------------|---------------|\n",
    "| Azure Subscription | With Contributor access to create resources | [Create free account](https://azure.microsoft.com/free/) |\n",
    "| Azure CLI | Version 2.50+ installed and configured | [Install Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) |\n",
    "| Python 3.8+ | With pip for package management | [Python downloads](https://www.python.org/downloads/) |\n",
    "| Azure OpenAI Access | Approved access to Azure OpenAI Service | [Request access](https://aka.ms/oai/access) |\n",
    "\n",
    "> ðŸ’¡ **Tip**: Run `az version` to verify your Azure CLI installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Login to Azure\n",
    "\n",
    "Authenticate with Azure using the interactive login flow. This will open a browser window for authentication.\n",
    "\n",
    "> ðŸ“– **Reference**: [Sign in with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Configuration Variables\n",
    "\n",
    "Configure the deployment parameters for your lab environment. A unique suffix is generated to ensure globally unique resource names.\n",
    "\n",
    "| Variable | Description | Value |\n",
    "|----------|-------------|-------|\n",
    "| `RESOURCE_GROUP` | Azure resource group name | `lab-token-rate-limiting` |\n",
    "| `LOCATION` | Azure region | `swedencentral` |\n",
    "| `APIM_NAME` | API Management instance name | Auto-generated |\n",
    "| `OPENAI_NAME` | Azure OpenAI resource name | Auto-generated |\n",
    "| `MODEL_NAME` | OpenAI model deployment | `gpt-4o-mini` |\n",
    "| `TPM_LIMIT` | Tokens Per Minute limit | `500` |\n",
    "\n",
    "> ðŸ“– **Reference**: [Azure regions with OpenAI availability](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Generate unique suffix\n",
    "suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))\n",
    "\n",
    "# Configuration\n",
    "RESOURCE_GROUP = \"lab-token-rate-limiting\"\n",
    "LOCATION = \"swedencentral\"\n",
    "APIM_NAME = f\"apim-tokenratelimit-{suffix}\"\n",
    "OPENAI_NAME = f\"openai-tokenratelimit-{suffix}\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "TPM_LIMIT = 500\n",
    "\n",
    "print(f\"APIM Name: {APIM_NAME}\")\n",
    "print(f\"OpenAI Name: {OPENAI_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Resource Group\n",
    "\n",
    "Create an Azure resource group to contain all lab resources. Resource groups provide a logical container for managing and organizing related resources.\n",
    "\n",
    "> ðŸ“– **Reference**: [Manage Azure resource groups](https://learn.microsoft.com/azure/azure-resource-manager/management/manage-resource-groups-cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az group create --name {RESOURCE_GROUP} --location {LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deploy Infrastructure\n",
    "\n",
    "Deploy the complete infrastructure using Bicep templates:\n",
    "\n",
    "| Resource | SKU/Tier | Purpose |\n",
    "|----------|----------|---------|\n",
    "| Azure API Management | BasicV2 | AI Gateway with GenAI policies support |\n",
    "| Azure OpenAI | Standard | LLM hosting (GPT-4o-mini) |\n",
    "\n",
    "**â±ï¸ Deployment Time**: ~5-10 minutes (APIM BasicV2 deploys faster than legacy tiers)\n",
    "\n",
    "> ðŸ“– **References**: \n",
    "> - [Deploy Bicep files with Azure CLI](https://learn.microsoft.com/azure/azure-resource-manager/bicep/deploy-cli)\n",
    "> - [APIM v2 tiers overview](https://learn.microsoft.com/azure/api-management/v2-service-tiers-overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az deployment group create --resource-group {RESOURCE_GROUP} --template-file main.bicep --parameters apimName={APIM_NAME} openAiName={OPENAI_NAME} location={LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Get APIM Subscription Key\n",
    "\n",
    "Retrieve the API Management gateway URL and subscription key for authentication. APIM uses subscription keys to control access to APIs.\n",
    "\n",
    "> ðŸ“– **Reference**: [Subscriptions in Azure API Management](https://learn.microsoft.com/azure/api-management/api-management-subscriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, json\n",
    "\n",
    "result = subprocess.run([\"az\", \"apim\", \"show\", \"--name\", APIM_NAME, \"--resource-group\", RESOURCE_GROUP, \"--query\", \"gatewayUrl\", \"-o\", \"tsv\"], capture_output=True, text=True)\n",
    "GATEWAY_URL = result.stdout.strip()\n",
    "\n",
    "result = subprocess.run([\"az\", \"apim\", \"subscription\", \"keys\", \"list\", \"--resource-group\", RESOURCE_GROUP, \"--service-name\", APIM_NAME, \"--subscription-id\", \"aoai-subscription\", \"-o\", \"json\"], capture_output=True, text=True)\n",
    "API_KEY = json.loads(result.stdout).get(\"primaryKey\", \"\")\n",
    "\n",
    "print(f\"Gateway URL: {GATEWAY_URL}\")\n",
    "print(f\"API Key: {API_KEY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Rate Limiting\n",
    "\n",
    "Send multiple requests to observe the `llm-token-limit` policy in action. With a 500 TPM limit, you should see rate limiting kick in after a few requests.\n",
    "\n",
    "### Expected Behavior\n",
    "\n",
    "| Response Code | Meaning | Action |\n",
    "|---------------|---------|--------|\n",
    "| `200 OK` | Request successful | Tokens counted against quota |\n",
    "| `429 Too Many Requests` | Rate limit exceeded | Wait for quota reset |\n",
    "\n",
    "> ðŸ“– **Reference**: [llm-token-limit policy error handling](https://learn.microsoft.com/azure/api-management/llm-token-limit-policy#errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "\n",
    "endpoint = f\"{GATEWAY_URL}/openai/deployments/{MODEL_NAME}/chat/completions?api-version=2024-02-01\"\n",
    "headers = {\"api-key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
    "payload = {\"messages\": [{\"role\": \"user\", \"content\": \"Say hello in 50 words\"}], \"max_tokens\": 100}\n",
    "\n",
    "for i in range(10):\n",
    "    r = requests.post(endpoint, headers=headers, json=payload, timeout=30)\n",
    "    if r.status_code == 200:\n",
    "        print(f\"Request {i+1}: âœ… Success\")\n",
    "    elif r.status_code == 429:\n",
    "        print(f\"Request {i+1}: âš ï¸ Rate limited\")\n",
    "    else:\n",
    "        print(f\"Request {i+1}: âŒ Error {r.status_code}\")\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Dashboard\n",
    "\n",
    "Launch the Streamlit dashboard to visualize token consumption and rate limiting in real-time.\n",
    "\n",
    "```bash\n",
    "pip install -r dashboard/requirements.txt\n",
    "cd dashboard && streamlit run app.py\n",
    "```\n",
    "\n",
    "Dashboard opens at http://localhost:8501\n",
    "\n",
    "> ðŸ“– **Reference**: [Streamlit documentation](https://docs.streamlit.io/)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Additional Monitoring Options\n",
    "\n",
    "For production scenarios, consider these Azure-native monitoring approaches:\n",
    "\n",
    "| Tool | Use Case | Documentation |\n",
    "|------|----------|---------------|\n",
    "| Azure Monitor | Metrics and alerts for APIM | [Monitor API Management](https://learn.microsoft.com/azure/api-management/api-management-howto-use-azure-monitor) |\n",
    "| Application Insights | End-to-end request tracing | [APIM with App Insights](https://learn.microsoft.com/azure/api-management/api-management-howto-app-insights) |\n",
    "| Log Analytics | Query and analyze logs | [Diagnostic logs](https://learn.microsoft.com/azure/api-management/api-management-howto-use-azure-monitor#resource-logs) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Cleanup\n",
    "\n",
    "Delete all resources to avoid ongoing charges. The resource group deletion removes all contained resources.\n",
    "\n",
    "> âš ï¸ **Warning**: This action is irreversible. Uncomment the code below only when you're ready to delete all lab resources.\n",
    "\n",
    "> ðŸ“– **Reference**: [Delete resource groups](https://learn.microsoft.com/azure/azure-resource-manager/management/delete-resource-group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete resources\n",
    "# !az group delete --name {RESOURCE_GROUP} --yes --no-wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“– Additional Resources\n",
    "\n",
    "### Microsoft Learn Modules\n",
    "- [Explore Azure API Management](https://learn.microsoft.com/training/modules/explore-api-management/) - Comprehensive APIM training\n",
    "- [Develop AI solutions with Azure OpenAI](https://learn.microsoft.com/training/paths/develop-ai-solutions-azure-openai/) - Full learning path\n",
    "- [Implement Azure OpenAI Service](https://learn.microsoft.com/training/modules/implement-azure-openai-service/) - Hands-on module\n",
    "\n",
    "### GitHub Samples & References\n",
    "- [Azure API Management GenAI Samples](https://github.com/Azure-Samples/AI-Gateway) - Official AI Gateway samples\n",
    "- [Azure OpenAI Samples](https://github.com/Azure-Samples/openai) - OpenAI code samples\n",
    "\n",
    "### Related Policies\n",
    "| Policy | Purpose | Documentation |\n",
    "|--------|---------|---------------|\n",
    "| `llm-token-limit` | Token-based rate limiting | [Docs](https://learn.microsoft.com/azure/api-management/llm-token-limit-policy) |\n",
    "| `llm-emit-token-metric` | Emit token usage metrics | [Docs](https://learn.microsoft.com/azure/api-management/llm-emit-token-metric-policy) |\n",
    "| `llm-semantic-cache-store` | Semantic caching for LLMs | [Docs](https://learn.microsoft.com/azure/api-management/llm-semantic-cache-store-policy) |\n",
    "| `azure-openai-emit-token-metric` | Azure OpenAI token metrics | [Docs](https://learn.microsoft.com/azure/api-management/azure-openai-emit-token-metric-policy) |\n",
    "\n",
    "---\n",
    "\n",
    "**Lab Version**: 1.0 | **Last Updated**: February 2026 | **Author**: Azure AI Gateway Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
